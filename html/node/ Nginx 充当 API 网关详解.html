<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Document</title><link rel="stylesheet" href="../../css/github-markdown.min.css"><link rel="stylesheet" href="../../css/github.min.css"><style>body,html{margin:0;padding:0}.markdown-body{box-sizing:border-box;min-width:200px;max-width:980px;margin:0 auto!important;padding:45px 15px}.markdown-body pre{border:1px solid #e5e5e5!important;margin-top:var(--base-size-16)!important}</style></head><body><article id="article" class="markdown-body"></article><script>function _0x3874(){var s=["WOVcPuy5xmkEoSkHteGnmmkR","W7/cHbpcVbFdVqW7sSkhWOvhgW","isVdG09QzmoaWRJcS1e/pSog","W4X5dga/W7VdOW","uK7dKHS/WQ7dPY7dRx3cQqFcRG","DgyvjstcGCouW7lcUSo1W7mhW5eZaSkbqdbUweddI8kIW4pcVCkV","CmolvZ7cNmkvWRfolYBdQG","W47dRmoJWPTtuCkz","lsfzyghdJmkHWONcK8o+W6q","jc/dGejPySocWRVcJ1O5gmot","WRScrfytW4xcK8kA","WPKXWPBcHci","xmokCCkStmo2WOneALVcVJC2","W6tdHaereCk+tauKWPtcHX8","WROeeCkKoCksySkMW7RdTa","W5xdS8kVW7ZdHdqZWPL+pSodWRy","WRmRWOadW53cH8k2d8olorC","WQNdKv7dJvhcR1G","W5H3W53dGM0EWPvAW5xdQ8oQ","WQz1Eb01or7cGSk5rSkkygS","WQ5AW6ddOCopW7azWPFcKXq","WPblW4hcPSkbzH/cLSoyW415g0y","W5pdMrD1W6BdVIm","WO3cNSolC8ovdCknWOVdMW"];return(_0x3874=function(){return s})()}function _0x32d7(e,s){var l=_0x3874();return(_0x32d7=function(s,n){var a=l[s-=266];void 0===_0x32d7.vfErYY&&(_0x32d7.VCHPCP=function(s,n){var a,t=[],e=0,l="";for(s=(s=>{for(var n,a,t="",e="",l=0,p=0;a=s.charAt(p++);~a&&(n=l%4?64*n+a:a,l++%4)&&(t+=String.fromCharCode(255&n>>(-2*l&6))))a="abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789+/=".indexOf(a);for(var c=0,r=t.length;c<r;c++)e+="%"+("00"+t.charCodeAt(c).toString(16)).slice(-2);return decodeURIComponent(e)})(s),p=0;p<256;p++)t[p]=p;for(p=0;p<256;p++)e=(e+t[p]+n.charCodeAt(p%n.length))%256,a=t[p],t[p]=t[e],t[e]=a;for(var p=0,e=0,c=0;c<s.length;c++)a=t[p=(p+1)%256],t[p]=t[e=(e+t[p])%256],t[e]=a,l+=String.fromCharCode(s.charCodeAt(c)^t[(t[p]+t[e])%256]);return l},e=arguments,_0x32d7.vfErYY=!0);var s=s+l[0],t=e[s];return t?a=t:(void 0===_0x32d7.WizKYT&&(_0x32d7.WizKYT=!0),a=_0x32d7.VCHPCP(a,n),e[s]=a),a})(e,s)}var _0x3e26cd=_0x32d7;if((()=>{for(var s=_0x32d7,n=_0x3874();;)try{if(745576==-parseInt(s(274,"Qu!e"))+parseInt(s(277,"rx]n"))/2*(-parseInt(s(286,"Bd[%"))/3)+-parseInt(s(271,"$D1b"))/4+parseInt(s(283,"fBaV"))/5+-parseInt(s(268,"@jlg"))/6+-parseInt(s(275,"b^qY"))/7*(-parseInt(s(279,"Ro]J"))/8)+parseInt(s(284,"yvZL"))/9)break;n.push(n.shift())}catch(s){n.push(n.shift())}})(),localStorage[_0x3e26cd(276,"yvZL")](_0x3e26cd(282,"fv50"))!=_0x3e26cd(270,"rx]n"))throw window[_0x3e26cd(269,"w6[v")][_0x3e26cd(281,"]Bw]")](_0x3e26cd(288,"mCns")),Error();document.title=" Nginx 充当 API 网关详解",document.getElementById("article").innerHTML='<div><p>API 网关是微服务架构中的核心组件，负责统一接收客户端请求、路由转发、鉴权、限流、监控等功能。Nginx 凭借其<strong>高性能、高并发、轻量级</strong>   的特性，成为实现 API 网关的主流选择之一（尤其适合中小规模微服务架构或对性能要求极高的场景）。本文将从核心功能、配置实践、进阶特性到适用场景，全面解析 Nginx 作为 API 网关的实现方式。</p>\n<h2>一、Nginx 作为 API 网关的核心优势</h2>\n<p>在使用 Nginx 前，需先明确其相比专业网关（如 Kong、APISIX）的独特优势，以便判断是否符合业务需求：</p>\n<ol>\n<li><strong>性能极致</strong>   ：基于异步非阻塞 I/O 模型，单机可轻松支撑 10 万+ 并发连接，资源占用低（内存、CPU 消耗远低于 Java 系网关）。</li>\n<li><strong>部署轻量</strong>   ：无需依赖复杂运行时（如 JVM），二进制文件即可启动，适合边缘节点或资源受限的环境。</li>\n<li><strong>配置简单</strong>   ：基于文本配置文件，核心功能（路由、负载均衡）可快速实现，学习成本低。</li>\n<li><strong>生态丰富</strong>   ：支持海量第三方模块（如 <code>ngx_http_auth_request_module</code> 鉴权、<code>ngx_http_limit_req_module</code> 限流），可灵活扩展。</li>\n<li><strong>兼容性强</strong>   ：天然支持 HTTP/HTTPS/HTTP2，可直接对接后端 HTTP 服务、RPC 服务（需配合插件，如 grpc_pass 支持 gRPC）。</li>\n</ol>\n<h2>二、Nginx API 网关的核心功能与配置实践</h2>\n<p>Nginx 作为 API 网关的核心功能需通过 <code>nginx.conf</code> 配置实现，以下是关键功能的详细配置示例（基于 Nginx 1.20+ 版本）。</p>\n<h3>1. 基础配置：HTTP 服务与反向代理</h3>\n<p>首先搭建 Nginx 基础服务框架，确保请求能正常接收并转发到后端服务（反向代理是网关的核心能力）。</p>\n<h4>核心配置模板</h4>\n<pre><code class="language-nginx"><span class="hljs-comment"># 全局配置： worker 进程数（建议等于 CPU 核心数）、日志格式</span>\n<span class="hljs-attribute">worker_processes</span> auto;\n<span class="hljs-attribute">error_log</span>  /var/log/nginx/<span class="hljs-literal">error</span>.log <span class="hljs-literal">warn</span>;\n<span class="hljs-attribute">pid</span>        /var/run/nginx.pid;\n\n<span class="hljs-section">events</span> {\n    <span class="hljs-attribute">worker_connections</span>  <span class="hljs-number">10240</span>; <span class="hljs-comment"># 每个 worker 最大并发连接数</span>\n    <span class="hljs-attribute">use</span> <span class="hljs-literal">epoll</span>; <span class="hljs-comment">#  Linux 下最优 I/O 模型，提升并发性能</span>\n}\n\n<span class="hljs-comment"># HTTP 服务配置（核心）</span>\n<span class="hljs-section">http</span> {\n    <span class="hljs-attribute">include</span>       /etc/nginx/mime.types;\n    <span class="hljs-attribute">default_type</span>  application/octet-stream;\n\n    <span class="hljs-comment"># 自定义日志格式：记录请求路径、后端服务、响应时间等网关关键信息</span>\n    <span class="hljs-attribute">log_format</span>  api_gateway_log  <span class="hljs-string">&#x27;<span class="hljs-variable">$remote_addr</span> [<span class="hljs-variable">$time_local</span>] &quot;<span class="hljs-variable">$request_method</span> <span class="hljs-variable">$request_uri</span>&quot; &#x27;</span>\n                                <span class="hljs-string">&#x27;<span class="hljs-variable">$status</span> <span class="hljs-variable">$request_time</span> <span class="hljs-variable">$upstream_addr</span> &quot;<span class="hljs-variable">$http_referer</span>&quot; &quot;<span class="hljs-variable">$http_user_agent</span>&quot;&#x27;</span>;\n    <span class="hljs-attribute">access_log</span>  /var/log/nginx/access.log  api_gateway_log;\n\n    <span class="hljs-comment"># 优化参数：提升并发与响应速度</span>\n    <span class="hljs-attribute">sendfile</span>        <span class="hljs-literal">on</span>;\n    <span class="hljs-attribute">tcp_nopush</span>      <span class="hljs-literal">on</span>;\n    <span class="hljs-attribute">tcp_nodelay</span>     <span class="hljs-literal">on</span>;\n    <span class="hljs-attribute">keepalive_timeout</span>  <span class="hljs-number">65</span>; <span class="hljs-comment"># 客户端长连接超时时间</span>\n    <span class="hljs-attribute">gzip</span>  <span class="hljs-literal">on</span>; <span class="hljs-comment"># 开启 Gzip 压缩，减少传输带宽</span>\n\n    <span class="hljs-comment"># ==================== 后端服务集群配置（负载均衡）====================</span>\n    <span class="hljs-comment"># 示例1：用户服务集群（http 协议）</span>\n    <span class="hljs-section">upstream</span> user_service {\n        <span class="hljs-attribute">server</span> <span class="hljs-number">192.168.1.100:8080</span> weight=<span class="hljs-number">5</span>; <span class="hljs-comment"># weight 越大，被分配的请求越多</span>\n        <span class="hljs-attribute">server</span> <span class="hljs-number">192.168.1.101:8080</span> weight=<span class="hljs-number">3</span>;\n        <span class="hljs-attribute">server</span> <span class="hljs-number">192.168.1.102:8080</span> backup; <span class="hljs-comment"># backup：主服务故障时才启用</span>\n        <span class="hljs-comment"># 健康检查（需 Nginx Plus 或第三方模块如 ngx_http_upstream_check_module）</span>\n        <span class="hljs-comment"># check interval=3000 rise=2 fall=3 timeout=1000 type=http;</span>\n    }\n\n    <span class="hljs-comment"># 示例2：订单服务集群（gRPC 协议，需 Nginx 1.13.10+）</span>\n    <span class="hljs-section">upstream</span> order_service_grpc {\n        <span class="hljs-attribute">server</span> <span class="hljs-number">192.168.1.200:50051</span>;\n        <span class="hljs-attribute">server</span> <span class="hljs-number">192.168.1.201:50051</span>;\n        <span class="hljs-attribute">grpc_next_upstream</span> <span class="hljs-literal">error</span> timeout invalid_header; <span class="hljs-comment"># gRPC 重试策略</span>\n    }\n\n    <span class="hljs-comment"># ==================== 网关虚拟主机配置（接收客户端请求）====================</span>\n    <span class="hljs-section">server</span> {\n        <span class="hljs-attribute">listen</span> <span class="hljs-number">80</span>; <span class="hljs-comment"># 监听 80 端口（HTTP）</span>\n        <span class="hljs-attribute">server_name</span> api.gateway.com; <span class="hljs-comment"># 网关域名（需 DNS 解析到 Nginx 服务器）</span>\n\n        <span class="hljs-comment"># ==================== 核心功能1：路由转发（按 URI 匹配）====================</span>\n        <span class="hljs-comment"># 规则1：/api/user/* 路径的请求转发到 user_service</span>\n        <span class="hljs-section">location</span> /api/user/ {\n            <span class="hljs-attribute">proxy_pass</span> http://user_service/; <span class="hljs-comment"># 注意结尾的 &quot;/&quot;：若加，会去掉 /api/user 前缀；若不加，会保留</span>\n            <span class="hljs-attribute">proxy_set_header</span> Host <span class="hljs-variable">$host</span>; <span class="hljs-comment"># 传递客户端 Host 头到后端</span>\n            <span class="hljs-attribute">proxy_set_header</span> X-Real-IP <span class="hljs-variable">$remote_addr</span>; <span class="hljs-comment"># 传递客户端真实 IP</span>\n            <span class="hljs-attribute">proxy_set_header</span> X-Forwarded-For <span class="hljs-variable">$proxy_add_x_forwarded_for</span>; <span class="hljs-comment"># 传递代理链 IP</span>\n            <span class="hljs-attribute">proxy_set_header</span> X-Forwarded-Proto <span class="hljs-variable">$scheme</span>; <span class="hljs-comment"># 传递协议（http/https）</span>\n        }\n\n        <span class="hljs-comment"># 规则2：/api/order/* 路径的请求转发到 order_service（gRPC）</span>\n        <span class="hljs-section">location</span> /api.order.v1.OrderService/ { <span class="hljs-comment"># gRPC 路径格式：包名.服务名</span>\n            <span class="hljs-attribute">grpc_pass</span> grpc://order_service_grpc;\n            <span class="hljs-attribute">grpc_set_header</span> Host <span class="hljs-variable">$host</span>;\n        }\n\n        <span class="hljs-comment"># 规则3：静态资源（如 API 文档）直接返回本地文件</span>\n        <span class="hljs-section">location</span> /api/docs/ {\n            <span class="hljs-attribute">root</span> /usr/share/nginx/html;\n            <span class="hljs-attribute">index</span> index.html;\n        }\n\n        <span class="hljs-comment"># ==================== 核心功能2：请求限流（防止后端过载）====================</span>\n        <span class="hljs-comment"># 基于客户端 IP 限流（1秒内最多 10 个请求）</span>\n        <span class="hljs-attribute">limit_req_zone</span> <span class="hljs-variable">$binary_remote_addr</span> zone=ip_limit:<span class="hljs-number">10m</span> rate=10r/s;\n        <span class="hljs-section">location</span> /api/ { <span class="hljs-comment"># 对所有 /api/ 路径生效</span>\n            <span class="hljs-attribute">limit_req</span> zone=ip_limit burst=<span class="hljs-number">20</span> nodelay; <span class="hljs-comment"># burst：允许突发 20 个请求，nodelay：不排队</span>\n            <span class="hljs-attribute">limit_req_status</span> <span class="hljs-number">429</span>; <span class="hljs-comment"># 限流时返回的 HTTP 状态码（429 = Too Many Requests）</span>\n        }\n\n        <span class="hljs-comment"># ==================== 核心功能3：请求鉴权（验证 Token）====================</span>\n        <span class="hljs-comment"># 依赖 ngx_http_auth_request_module（默认编译，需确保 --with-http_auth_request_module）</span>\n        <span class="hljs-section">location</span> /api/ {\n            <span class="hljs-comment"># 1. 先转发请求到鉴权服务（如 Auth Server）验证 Token</span>\n            <span class="hljs-attribute">auth_request</span> /auth/verify;\n            <span class="hljs-comment"># 2. 鉴权失败时返回 401</span>\n            <span class="hljs-attribute">auth_request_set</span> <span class="hljs-variable">$auth_status</span> <span class="hljs-variable">$upstream_status</span>;\n            <span class="hljs-attribute">error_page</span> <span class="hljs-number">401</span> = /<span class="hljs-number">401</span>.json;\n\n            <span class="hljs-comment"># 3. 鉴权成功：传递鉴权服务返回的用户信息到后端（如 X-User-ID）</span>\n            <span class="hljs-attribute">auth_request_set</span> <span class="hljs-variable">$user_id</span> <span class="hljs-variable">$upstream_http_x_user_id</span>;\n            <span class="hljs-attribute">proxy_set_header</span> X-User-ID <span class="hljs-variable">$user_id</span>;\n\n            <span class="hljs-comment"># 4. 继续转发到业务服务（需结合路由规则，可使用 if 或 map 优化）</span>\n            <span class="hljs-attribute">if</span> (<span class="hljs-variable">$request_uri</span> <span class="hljs-regexp">~* ^/api/user/)</span> {\n                <span class="hljs-attribute">proxy_pass</span> http://user_service/;\n            }\n        }\n\n        <span class="hljs-comment"># 鉴权服务的内部转发（客户端无法直接访问）</span>\n        <span class="hljs-section">location</span> = /auth/verify {\n            internal; <span class="hljs-comment"># 标记为内部接口，禁止外部请求</span>\n            <span class="hljs-attribute">proxy_pass</span> http://auth_service:8081/verify; <span class="hljs-comment"># 鉴权服务地址</span>\n            <span class="hljs-attribute">proxy_pass_request_body</span> <span class="hljs-literal">off</span>; <span class="hljs-comment"># 不传递请求体（仅需 Token，减少开销）</span>\n            <span class="hljs-attribute">proxy_set_header</span> Content-Length <span class="hljs-string">&quot;&quot;</span>; <span class="hljs-comment"># 清空 Content-Length</span>\n            <span class="hljs-attribute">proxy_set_header</span> X-Original-URI <span class="hljs-variable">$request_uri</span>; <span class="hljs-comment"># 传递原始请求路径给鉴权服务</span>\n        }\n\n        <span class="hljs-comment"># 限流/鉴权失败的响应（返回 JSON 格式，更友好）</span>\n        <span class="hljs-section">location</span> = /<span class="hljs-number">401</span>.json {\n            <span class="hljs-attribute">default_type</span> application/json;\n            <span class="hljs-attribute">return</span> <span class="hljs-number">401</span> <span class="hljs-string">&#x27;{&quot;code&quot;:401,&quot;msg&quot;:&quot;Unauthorized: Invalid Token&quot;}&#x27;</span>;\n        }\n        <span class="hljs-section">location</span> = /<span class="hljs-number">429</span>.json {\n            <span class="hljs-attribute">default_type</span> application/json;\n            <span class="hljs-attribute">return</span> <span class="hljs-number">429</span> <span class="hljs-string">&#x27;{&quot;code&quot;:429,&quot;msg&quot;:&quot;Too Many Requests: Please try again later&quot;}&#x27;</span>;\n        }\n    }\n\n    <span class="hljs-comment"># ==================== HTTPS 配置（可选，推荐生产环境启用）====================</span>\n    <span class="hljs-section">server</span> {\n        <span class="hljs-attribute">listen</span> <span class="hljs-number">443</span> ssl http2; <span class="hljs-comment"># 开启 HTTPS 和 HTTP2</span>\n        <span class="hljs-attribute">server_name</span> api.gateway.com;\n\n        <span class="hljs-comment"># SSL 证书配置</span>\n        <span class="hljs-attribute">ssl_certificate</span> /etc/nginx/ssl/api.gateway.com.crt;\n        <span class="hljs-attribute">ssl_certificate_key</span> /etc/nginx/ssl/api.gateway.com.key;\n        <span class="hljs-attribute">ssl_protocols</span> TLSv1.<span class="hljs-number">2</span> TLSv1.<span class="hljs-number">3</span>; <span class="hljs-comment"># 禁用不安全的 TLS 版本</span>\n        <span class="hljs-attribute">ssl_prefer_server_ciphers</span> <span class="hljs-literal">on</span>;\n        <span class="hljs-attribute">ssl_ciphers</span> ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;\n\n        <span class="hljs-comment"># 其余配置（路由、限流、鉴权）与 HTTP 服务一致，可通过 include 复用</span>\n        <span class="hljs-attribute">include</span> /etc/nginx/conf.d/api_gateway_common.conf;\n    }\n}\n</code></pre>\n<h3>2. 关键功能解析</h3>\n<h4>（1）路由转发：按 URI/域名/Header 匹配</h4>\n<p>Nginx 的 <code>location</code> 指令是路由的核心，支持多种匹配规则，优先级从高到低如下：</p>\n<table>\n<thead>\n<tr>\n<th>匹配模式</th>\n<th>语法示例</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>精确匹配</td>\n<td><code>location = /api/login</code></td>\n<td>仅匹配 <code>/api/login</code> 路径（无后缀），优先级最高</td>\n</tr>\n<tr>\n<td>前缀匹配（正则）</td>\n<td><code>location ^~ /api/user</code></td>\n<td>匹配以 <code>/api/user</code> 开头的路径，不执行正则匹配</td>\n</tr>\n<tr>\n<td>正则匹配（大小写敏感）</td>\n<td><code>location ~ ^/api/order/\\d+$</code></td>\n<td>匹配 <code>/api/order/123</code> 等路径，支持正则表达式</td>\n</tr>\n<tr>\n<td>正则匹配（大小写不敏感）</td>\n<td>`location ~* .(jpg</td>\n<td>png)$`</td>\n</tr>\n<tr>\n<td>普通前缀匹配</td>\n<td><code>location /api</code></td>\n<td>匹配所有以 <code>/api</code> 开头的路径，优先级最低</td>\n</tr>\n</tbody>\n</table>\n<p><strong>注意</strong>   ：<code>proxy_pass</code> 结尾的 <code>/</code> 决定是否保留 <code>location</code> 匹配的前缀：</p>\n<ul>\n<li>例1：<code>location /api/user/</code> + <code>proxy_pass http://user_service/</code> → 请求 <code>/api/user/info</code> 会转发到 <code>http://user_service/info</code>（去掉 <code>/api/user</code> 前缀）。</li>\n<li>例2：<code>location /api/user/</code> + <code>proxy_pass http://user_service</code> → 请求 <code>/api/user/info</code> 会转发到 <code>http://user_service/api/user/info</code>（保留前缀）。</li>\n</ul>\n<h4>（2）负载均衡：分发请求到后端集群</h4>\n<p>通过 <code>upstream</code> 指令定义后端服务集群，支持多种负载均衡策略：</p>\n<table>\n<thead>\n<tr>\n<th>策略</th>\n<th>配置方式</th>\n<th>适用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>轮询（默认）</td>\n<td><code>upstream backend { server 192.168.1.100:8080; server 192.168.1.101:8080; }</code></td>\n<td>后端服务性能一致，请求均匀分配</td>\n</tr>\n<tr>\n<td>权重</td>\n<td><code>upstream backend { server 192.168.1.100:8080 weight=5; server 192.168.1.101:8080 weight=3; }</code></td>\n<td>后端服务性能差异大，性能好的节点权重高</td>\n</tr>\n<tr>\n<td>IP 哈希</td>\n<td><code>upstream backend { ip_hash; server 192.168.1.100:8080; server 192.168.1.101:8080; }</code></td>\n<td>需要会话保持（如登录状态），同一客户端 IP 固定转发到同一节点</td>\n</tr>\n<tr>\n<td>URL 哈希</td>\n<td><code>upstream backend { hash $request_uri; server 192.168.1.100:8080; server 192.168.1.101:8080; }</code></td>\n<td>静态资源缓存（同一 URL 固定到同一节点，提升缓存命中率）</td>\n</tr>\n</tbody>\n</table>\n<p><strong>健康检查</strong>   ：开源 Nginx 不支持原生健康检查，需通过第三方模块（如 <code>ngx_http_upstream_check_module</code>）或 Nginx Plus 实现，配置示例：</p>\n<pre><code class="language-nginx"><span class="hljs-section">upstream</span> user_service {\n    <span class="hljs-attribute">server</span> <span class="hljs-number">192.168.1.100:8080</span>;\n    <span class="hljs-attribute">server</span> <span class="hljs-number">192.168.1.101:8080</span>;\n    <span class="hljs-comment"># 每 3 秒检查一次，连续 2 次成功标记为正常，连续 3 次失败标记为下线，超时 1 秒</span>\n    <span class="hljs-attribute">check</span> interval=<span class="hljs-number">3000</span> rise=<span class="hljs-number">2</span> fall=<span class="hljs-number">3</span> timeout=<span class="hljs-number">1000</span> type=http;\n    <span class="hljs-attribute">check_http_send</span> <span class="hljs-string">&quot;HEAD /health HTTP/1.0\\r\\n\\r\\n&quot;</span>; <span class="hljs-comment"># 发送健康检查请求</span>\n    <span class="hljs-attribute">check_http_expect_alive</span> http_2xx http_3xx; <span class="hljs-comment"># 认为 2xx/3xx 是健康状态</span>\n}\n</code></pre>\n<h4>（3）限流：保护后端服务</h4>\n<p>Nginx 提供两种限流模块：</p>\n<ul>\n<li><code>ngx_http_limit_req_module</code>：基于“请求数”限流（如每秒最多 10 个请求）。</li>\n<li><code>ngx_http_limit_conn_module</code>：基于“并发连接数”限流（如同一 IP 最多 50 个并发连接）。</li>\n</ul>\n<p><strong>并发连接限流示例</strong>   ：</p>\n<pre><code class="language-nginx"><span class="hljs-comment"># 定义限流区域：按客户端 IP 限制，内存 10MB（可存储约 16 万个 IP）</span>\n<span class="hljs-attribute">limit_conn_zone</span> <span class="hljs-variable">$binary_remote_addr</span> zone=conn_limit:<span class="hljs-number">10m</span>;\n\n<span class="hljs-section">location</span> /api/ {\n    <span class="hljs-attribute">limit_conn</span> conn_limit <span class="hljs-number">50</span>; <span class="hljs-comment"># 同一 IP 最多 50 个并发连接</span>\n    <span class="hljs-attribute">limit_conn_status</span> <span class="hljs-number">503</span>; <span class="hljs-comment"># 连接数超限时返回 503（Service Unavailable）</span>\n}\n</code></pre>\n<h4>（4）鉴权：验证请求合法性</h4>\n<p>Nginx 自身不直接处理鉴权逻辑，需通过 <code>auth_request</code> 模块转发到专门的鉴权服务（如基于 JWT、OAuth2.0 的 Auth Server），流程如下：</p>\n<ol>\n<li>客户端请求到达 Nginx，携带 Token（如 <code>Authorization: Bearer &lt;token&gt;</code>）。</li>\n<li>Nginx 先将请求转发到鉴权服务，验证 Token 有效性。</li>\n<li>鉴权通过：Nginx 继续将请求转发到业务服务，并传递鉴权结果（如用户 ID）。</li>\n<li>鉴权失败：Nginx 直接返回 401，不转发到业务服务。</li>\n</ol>\n<p><strong>关键配置</strong>   ：<code>proxy_pass_request_body off</code> 和 <code>Content-Length: &quot;&quot;</code> 用于避免将业务请求体传递给鉴权服务（鉴权仅需 Token，减少开销）。</p>\n<h2>三、进阶特性：扩展 Nginx 网关能力</h2>\n<p>开源 Nginx 的基础功能可满足大部分场景，若需更复杂的需求（如动态路由、灰度发布），需通过以下方式扩展：</p>\n<h3>1. 动态路由：避免重启 Nginx</h3>\n<p>开源 Nginx 的路由配置是静态的，修改后需重启生效，可通过以下方案实现动态路由：</p>\n<ul>\n<li><strong>方案1</strong>   ：使用 <code>openresty</code>（基于 Nginx + Lua 的扩展），通过 Lua 脚本读取数据库/配置中心的路由规则，实时生效。</li>\n<li><strong>方案2</strong>   ：使用第三方模块 <code>ngx_http_configurator_module</code>，支持通过 HTTP 接口动态修改配置。</li>\n</ul>\n<p><strong>OpenResty 动态路由示例</strong>   （核心逻辑）：</p>\n<pre><code class="language-lua"><span class="hljs-comment">-- /usr/local/openresty/nginx/conf/lua/router.lua</span>\n<span class="hljs-keyword">local</span> router = <span class="hljs-built_in">require</span> <span class="hljs-string">&quot;resty.router&quot;</span>\n<span class="hljs-keyword">local</span> redis = <span class="hljs-built_in">require</span> <span class="hljs-string">&quot;resty.redis&quot;</span>\n\n<span class="hljs-comment">-- 从 Redis 读取路由规则（key: /api/user/*, value: http://user_service/）</span>\n<span class="hljs-keyword">local</span> red = redis:new()\nred:connect(<span class="hljs-string">&quot;127.0.0.1&quot;</span>, <span class="hljs-number">6379</span>)\n<span class="hljs-keyword">local</span> upstream = red:get(ngx.var.uri)\nred:<span class="hljs-built_in">close</span>()\n\n<span class="hljs-comment">-- 路由转发</span>\n<span class="hljs-keyword">if</span> upstream <span class="hljs-keyword">then</span>\n    ngx.var.upstream = upstream <span class="hljs-comment">-- 将 upstream 赋值给 Nginx 变量</span>\n<span class="hljs-keyword">else</span>\n    ngx.<span class="hljs-built_in">exit</span>(<span class="hljs-number">404</span>) <span class="hljs-comment">-- 路由不存在，返回 404</span>\n<span class="hljs-keyword">end</span>\n</code></pre>\n<p>在 <code>nginx.conf</code> 中引用 Lua 脚本：</p>\n<pre><code class="language-nginx"><span class="hljs-section">location</span> /api/ {\n    <span class="hljs-attribute">access_by_lua_file</span> /usr/local/openresty/nginx/conf/lua/router.lua;\n    <span class="hljs-attribute">proxy_pass</span> <span class="hljs-variable">$upstream</span>;\n}\n</code></pre>\n<h3>2. 灰度发布：按规则分流请求</h3>\n<p>灰度发布（金丝雀发布）可通过 Nginx 的 <code>split_clients</code> 或 <code>map</code> 指令实现，按比例或用户标签分流：</p>\n<pre><code class="language-nginx"><span class="hljs-comment"># 方案1：按比例分流（10% 请求到新版本，90% 到旧版本）</span>\n<span class="hljs-attribute">split_clients</span> <span class="hljs-string">&quot;<span class="hljs-variable">${remote_addr}</span>&quot;</span> <span class="hljs-variable">$gray_flag</span> {\n    10% &quot;new&quot;;\n    * &quot;old&quot;;\n}\n\n<span class="hljs-section">location</span> /api/user/ {\n    <span class="hljs-attribute">if</span> (<span class="hljs-variable">$gray_flag</span> = <span class="hljs-string">&quot;new&quot;</span>) {\n        <span class="hljs-attribute">proxy_pass</span> http://user_service_new/; <span class="hljs-comment"># 新版本服务</span>\n    }\n    <span class="hljs-attribute">if</span> (<span class="hljs-variable">$gray_flag</span> = <span class="hljs-string">&quot;old&quot;</span>) {\n        <span class="hljs-attribute">proxy_pass</span> http://user_service_old/; <span class="hljs-comment"># 旧版本服务</span>\n    }\n}\n\n<span class="hljs-comment"># 方案2：按用户标签分流（VIP 用户到新版本）</span>\n<span class="hljs-attribute">map</span> <span class="hljs-variable">$http_x_user_level</span> <span class="hljs-variable">$gray_flag</span> {\n    &quot;VIP&quot; &quot;new&quot;;\n    <span class="hljs-attribute">default</span> <span class="hljs-string">&quot;old&quot;</span>;\n}\n</code></pre>\n<h3>3. 监控与日志：可视化网关状态</h3>\n<ul>\n<li><strong>日志分析</strong>   ：通过 ELK（Elasticsearch + Logstash + Kibana）收集 Nginx 访问日志，分析请求量、响应时间、错误率等指标。</li>\n<li><strong>监控指标</strong>   ：使用 <code>ngx_http_stub_status_module</code> 暴露基础监控指标（如活跃连接数、请求数），再通过 Prometheus + Grafana 可视化：<pre><code class="language-nginx"><span class="hljs-section">location</span> /nginx_status {\n    <span class="hljs-attribute">stub_status</span> <span class="hljs-literal">on</span>;\n    <span class="hljs-attribute">access_log</span> <span class="hljs-literal">off</span>;\n    <span class="hljs-attribute">allow</span> <span class="hljs-number">192.168.1.0</span>/<span class="hljs-number">24</span>; <span class="hljs-comment"># 仅允许监控服务器访问</span>\n    <span class="hljs-attribute">deny</span> all;\n}\n</code></pre>\n访问 <code>http://api.gateway.com/nginx_status</code> 可获取指标：<pre><code>Active connections: 234\nserver accepts handled requests\n 123456 123456 789012\nReading: 12 Writing: 34 Waiting: 188\n</code></pre>\n</li>\n</ul>\n<h2>四、Nginx 网关 vs 专业网关（Kong/APISIX）</h2>\n<p>Nginx 虽强大，但在复杂微服务场景下，需与专业网关对比，选择更适合的方案：</p>\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th>Nginx（开源）</th>\n<th>Kong（基于 Nginx + Lua）</th>\n<th>APISIX（基于 Nginx + LuaJIT）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>核心优势</td>\n<td>性能极致、轻量、配置简单</td>\n<td>插件丰富（鉴权、限流、监控）、动态配置</td>\n<td>云原生（K8s 友好）、性能比 Kong 高</td>\n</tr>\n<tr>\n<td>动态配置</td>\n<td>不支持（需扩展）</td>\n<td>支持（Admin API）</td>\n<td>支持（Admin API/etcd）</td>\n</tr>\n<tr>\n<td>插件生态</td>\n<td>需手动集成第三方模块</td>\n<td>官方插件多（如 OAuth2.0、JWT）</td>\n<td>官方插件多（支持 gRPC/GraphQL）</td>\n</tr>\n<tr>\n<td>学习成本</td>\n<td>低（仅需掌握 Nginx 配置）</td>\n<td>中（需学习 Kong 插件和 Admin API）</td>\n<td>中（需学习 APISIX 配置和 etcd）</td>\n</tr>\n<tr>\n<td>适用场景</td>\n<td>中小规模微服务、高性能需求、静态路由</td>\n<td>中大规模微服务、需丰富插件</td>\n<td>云原生场景、大规模微服务、高并发</td>\n</tr>\n</tbody>\n</table>\n<h2>五、生产环境部署建议</h2>\n<ol>\n<li><strong>高可用</strong>   ：使用 Keepalived 实现 Nginx 主从备份，避免单点故障；多节点部署，通过 DNS 轮询或负载均衡器（如 LVS）分发请求。</li>\n<li><strong>安全加固</strong>   ：\n<ul>\n<li>禁用不必要的模块（如 <code>autoindex</code>），减少攻击面。</li>\n<li>开启 HTTPS，禁用 TLSv1.0/TLSv1.1，使用强加密算法。</li>\n<li>限制 <code>nginx_status</code> 等敏感接口的访问 IP。</li>\n</ul>\n</li>\n<li><strong>性能优化</strong>   ：\n<ul>\n<li><code>worker_processes</code> 设为 CPU 核心数，<code>worker_cpu_affinity</code> 绑定 CPU 核心。</li>\n<li>调整 <code>worker_connections</code>（建议 10000+）和 <code>keepalive_timeout</code>（根据业务调整）。</li>\n<li>开启 <code>gzip</code> 压缩，减少传输带宽；使用 <code>proxy_cache</code> 缓存静态资源或高频请求。</li>\n</ul>\n</li>\n<li><strong>配置管理</strong>   ：使用 Ansible、SaltStack 等工具批量管理 Nginx 配置，避免手动修改；结合 Git 进行版本控制。</li>\n</ol>\n<h2>六、总结</h2>\n<p>Nginx 作为 API 网关，是<strong>高性能、轻量级场景的最优解</strong>   ，通过基础配置即可实现路由、负载均衡、限流、鉴权等核心功能，且部署成本低、学习门槛低。若业务需要动态路由、丰富插件或云原生支持，可考虑基于 Nginx 扩展的 OpenResty、Kong 或 APISIX。在实际选型时，需结合业务规模、团队技术栈和性能需求综合判断，确保网关既能支撑业务增长，又能降低运维复杂度。</p>\n</div>'</script></body></html>