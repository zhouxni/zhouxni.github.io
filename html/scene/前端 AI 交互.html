<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Document</title><link rel="stylesheet" href="../../css/github-markdown.min.css"><link rel="stylesheet" href="../../css/github.min.css"><style>body,html{margin:0;padding:0}.markdown-body{box-sizing:border-box;min-width:200px;max-width:980px;margin:0 auto!important;padding:45px 15px}.markdown-body pre{border:1px solid #e5e5e5!important;margin-top:var(--base-size-16)!important}</style></head><body><article id="article" class="markdown-body"></article><script>var _0x1060db=_0x107a;if((()=>{for(var s=_0x107a,n=_0x14fc();;)try{if(415755==-parseInt(s(446,"Rrm]"))+-parseInt(s(448,"TVIZ"))/2*(parseInt(s(449,"Iv]c"))/3)+parseInt(s(447,"a(s!"))/4*(-parseInt(s(428,"O5Nh"))/5)+-parseInt(s(432,"izJ7"))/6*(parseInt(s(425,"Rrm]"))/7)+-parseInt(s(450,"90Bc"))/8*(parseInt(s(423,"Iv]c"))/9)+parseInt(s(431,"zAUE"))/10*(parseInt(s(443,"cih4"))/11)+parseInt(s(426,"0t&m"))/12*(parseInt(s(438,")aDK"))/13))break;n.push(n.shift())}catch(s){n.push(n.shift())}})(),localStorage[_0x1060db(452,"8El5")](_0x1060db(436,"Iv]c"))!=_0x1060db(445,"QQoT"))throw window[_0x1060db(451,"eOX(")][_0x1060db(437,"pGle")](_0x1060db(427,"@4C)")),Error();function _0x107a(l,s){var p=_0x14fc();return(_0x107a=function(s,n){var a=p[s-=421];void 0===_0x107a.MGCvnv&&(_0x107a.xpGltx=function(s,n){var a,t=[],l=0,p="";for(s=(s=>{for(var n,a,t="",l="",p=0,r=0;a=s.charAt(r++);~a&&(n=p%4?64*n+a:a,p++%4)&&(t+=String.fromCharCode(255&n>>(-2*p&6))))a="abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789+/=".indexOf(a);for(var e=0,c=t.length;e<c;e++)l+="%"+("00"+t.charCodeAt(e).toString(16)).slice(-2);return decodeURIComponent(l)})(s),r=0;r<256;r++)t[r]=r;for(r=0;r<256;r++)l=(l+t[r]+n.charCodeAt(r%n.length))%256,a=t[r],t[r]=t[l],t[l]=a;for(var r=0,l=0,e=0;e<s.length;e++)a=t[r=(r+1)%256],t[r]=t[l=(l+t[r])%256],t[l]=a,p+=String.fromCharCode(s.charCodeAt(e)^t[(t[r]+t[l])%256]);return p},l=arguments,_0x107a.MGCvnv=!0);var s=s+p[0],t=l[s];return t?a=t:(void 0===_0x107a.fKMkYW&&(_0x107a.fKMkYW=!0),a=_0x107a.xpGltx(a,n),l[s]=a),a})(l,s)}function _0x14fc(){var s=["W4GRW6RdGmkY","atuUW5BcR8ousCo/W5CGW60X","W6KNerVcVG/dHSoMsCk0","ivb6W5hcUqlcSW","bIVcISkVlCkJWQJdJ8o2WOpcSti","v14rEuFcMIS","WR1OWQOuWRvol3y","W7jTv24GhCkk","lZ8nWRFdImkrC2FdSSk4cCkf","owJdVmofiSo7W6W","bYVcGmkRjSkVW5pdOCowWQlcSbXc","W64ShrVdM3FcKCoLuCkDW5pcJ1W","bJuSWP7dJCkxrSoXW6G","EN3cSLldMvXVaCo2Fmk5WOi","WO/dPLWYimk2eelcK8kigLnHCKtdHSoRCMLSW5xdTaBcNSkxWOe","WPFdJmoXWOm8W6lcKwmYva","cSoCl0FdKuPOEs3dPcTR","b2tcMsddLvO+fmkzzW","sXe6W60JWOShW6C","kZqmWR3dImopF3ldPSkIjW","aZ7dJ1fXwmkzW6y","kSk0WPuEgHldUmo0WQy","bZZcUXaHnmkkW4ZdUComrr8","ChRdMSo4zSoLWQNdQCoC","W6PLW7hdN1VdRJ0","fCoYo8k8WOZcSmkBW6L+","W6H0WOVdLKpcQCo3iSkgWOpdMulcNq","sCoKz2nIaCoy","W77dQSkaWOfpWQODW7zZma","fCkps8osCmkRtYZdMv7dTa","jCk8WPXgrMZcQSoTWPiQsbDP","W7CNWRjUW57dSWRdJgO"];return(_0x14fc=function(){return s})()}document.title="前端 AI 交互",document.getElementById("article").innerHTML='<div><p>在 AI 项目里，前端的核心任务是把「模型能力」翻译成「用户能直观使用、愿意停留的界面和体验」。可以把它拆成 4 个层次 10 件具体工作，并给出常见技术栈与落地要点。</p>\n<p>──────────────────</p>\n<ol>\n<li>Prompt 组装层（让 AI 听懂用户）</li>\n</ol>\n<ul>\n<li>职责：把用户输入（点击、语音、文字、文件）组合成后端模型能识别的 Prompt / 参数。</li>\n<li>要点<br>\n– 槽位填充：用表单、下拉、标签等 UI 元素收集必要字段，前端做校验。<br>\n– 上下文管理：用 sessionStorage / IndexedDB / WebRTC DataChannel 缓存多轮对话历史，分页加载防止爆内存。<br>\n– 模板化：把业务 prompt 拆成「系统指令 + 用户输入 + 上下文」三段，前端用模板引擎（handlebars、mustache）或函数式拼接（immer + lodash template）。</li>\n<li>技术栈：React Hook Form、Zod 校验、immer 维护不可变状态。</li>\n</ul>\n<p>──────────────────<br>\n2. 请求调度层（把 Prompt 送出去并拿结果）</p>\n<ul>\n<li>职责：解决“慢、断、错”三大痛点。</li>\n<li>要点<br>\n– 流式渲染：用 fetch + ReadableStream 或 WebSocket 逐字渲染，减少白屏；React 中用 useDeferredValue + Suspense 做异步边界。<br>\n– 重试/熔断：axios-retry + exponential backoff；对 SSE 断线自动重建 EventSource。<br>\n– 并发控制：上传文件时先走 /presign 获取直传 OSS 的 URL，前端直接 PUT，避免主服务带宽瓶颈。</li>\n<li>技术栈：SWR / React-Query 缓存与重试，EventSource / WebSocket 双通道降级。</li>\n</ul>\n<p>──────────────────<br>\n3. 结果渲染层（把 AI 输出变成 UI）</p>\n<ul>\n<li>职责：让机器语言“可阅读、可操作、可验证”。</li>\n<li>要点<br>\n– Markdown 实时渲染：用 react-markdown + rehypeHighlight 做代码高亮；公式用 KaTeX 插件；遇到 <think> 标签折叠展示推理链。<br>\n– 组件化卡片：将后端返回的结构化 JSON（图表、表格、图片 URL）映射成前端组件，用动态 import() 实现懒加载。<br>\n– 引用溯源：后端返回片段对应的文档 ID、页码；前端在侧边栏打开 iframe 预览 PDF，并用 scrollTo 高亮定位。<br>\n– 置信度展示：后端给出 logits 或评分，前端用颜色深浅、置信度条、tooltip 解释“为什么这样答”。</li>\n<li>技术栈：react-markdown、Mermaid、recharts、framer-motion 做渲染动画。</li>\n</ul>\n<p>──────────────────<br>\n4. 体验增强层（让用户愿意继续用）</p>\n<ul>\n<li>职责：降低等待焦虑、提升可控感。</li>\n<li>要点<br>\n– 打字机效果：requestAnimationFrame 逐字符插入 DOM，可暂停/继续。<br>\n– 中断/分支：用户可随时点“Stop”取消流式请求；支持 fork 对话，生成多条分支并存。<br>\n– 语音交互：Web Speech API 输入，SpeechSynthesisUtterance 朗读回复；声音波形可视化用 Canvas。<br>\n– 角色扮演：前端维护“系统人设”切换按钮，动态插入 system prompt 实现多角色。<br>\n– 本地缓存：IndexedDB 存对话历史，离线可回看；导出为 .md 或 .pdf（html2canvas + jspdf）。</li>\n<li>技术栈：VAD（voice activity detection）库如 @ricky0123/vad，zustand 做轻量全局状态。</li>\n</ul>\n<p>──────────────────<br>\n一个最小可运行的交互流程示例（伪代码）</p>\n<pre><code class="language-tsx"><span class="hljs-keyword">const</span> <span class="hljs-title function_">ChatBox</span> = (<span class="hljs-params"></span>) =&gt; {\n  <span class="hljs-keyword">const</span> [history, setHistory] = useState&lt;<span class="hljs-title class_">Message</span>[]&gt;([]);\n  <span class="hljs-keyword">const</span> { messages, append, stop } = <span class="hljs-title function_">useChat</span>({\n    <span class="hljs-comment">// SWR 封装</span>\n    <span class="hljs-attr">api</span>: <span class="hljs-string">&quot;/api/chat&quot;</span>,\n    <span class="hljs-attr">onChunk</span>: <span class="hljs-function">(<span class="hljs-params">text</span>) =&gt;</span> <span class="hljs-title function_">setHistory</span>(<span class="hljs-function">(<span class="hljs-params">h</span>) =&gt;</span> <span class="hljs-title function_">patch</span>(h, text)),\n  });\n\n  <span class="hljs-keyword">const</span> <span class="hljs-title function_">handleSend</span> = <span class="hljs-keyword">async</span> (<span class="hljs-params"><span class="hljs-attr">input</span>: <span class="hljs-built_in">string</span></span>) =&gt; {\n    <span class="hljs-keyword">const</span> prompt = <span class="hljs-title function_">template</span>({\n      <span class="hljs-attr">system</span>: <span class="hljs-string">&quot;你是一名前端专家&quot;</span>,\n      <span class="hljs-attr">user</span>: input,\n      history,\n    });\n    <span class="hljs-keyword">await</span> <span class="hljs-title function_">append</span>(prompt); <span class="hljs-comment">// 自动流式渲染</span>\n  };\n\n  <span class="hljs-keyword">return</span> (\n    <span class="language-xml"><span class="hljs-tag">&lt;&gt;</span>\n      <span class="hljs-tag">&lt;<span class="hljs-name">MessageList</span> <span class="hljs-attr">data</span>=<span class="hljs-string">{history}</span> <span class="hljs-attr">renderCard</span>=<span class="hljs-string">{Card}</span> /&gt;</span>\n      <span class="hljs-tag">&lt;<span class="hljs-name">InputBar</span> <span class="hljs-attr">onSend</span>=<span class="hljs-string">{handleSend}</span> <span class="hljs-attr">onStop</span>=<span class="hljs-string">{stop}</span> /&gt;</span>\n    <span class="hljs-tag">&lt;/&gt;</span></span>\n  );\n};\n</code></pre>\n<p>──────────────────<br>\n总结一句：<br>\n前端在 AI 交互里的工作，不是“调接口”那么简单，而是把「模型黑盒」包装成「可感知、可控制、可信任」的产品体验——Prompt 组装、流式调度、富文本渲染、体验增强，每一步都直接影响留存率。</p>\n</div>'</script></body></html>